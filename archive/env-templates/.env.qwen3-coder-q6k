# Qwen3-Coder-Next Q6_K — standard 6-bit quantization (non-UD)
#
# Standard Q6_K quantization without Unsloth Dynamic optimization.
# 256K context. Similar size to UD-Q6_K_XL (~65.5 GB).
#
# Note: The -ot regex uses the same layer split as UD-Q6_K_XL (13+6) as a
# reasonable starting point since the model sizes are similar. Adjust based
# on actual VRAM usage — you may be able to fit more or fewer layers.
#
# For most use cases, prefer .env.qwen3-coder (UD-Q6_K_XL) which provides
# better quality through smarter bit allocation on router tensors.
#
# See docs/llama-cpp-flags-and-qwen3-strategy.md for full details.

MODEL=Qwen3-Coder-Next/Q6_K/Qwen3-Coder-Next-Q6_K-00001-of-00003.gguf
CTX_SIZE=262144
N_GPU_LAYERS=99
FIT=off
EXTRA_ARGS=--jinja -np 1 -b 2048 -ub 2048 --no-context-shift --temp 1.0 --top-p 0.95 --top-k 40 --min-p 0 -ot blk\.([0-9]|1[0-2])\.=CUDA0,blk\.(1[3-8])\.=CUDA1,exps=CPU
