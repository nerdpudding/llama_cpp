# Qwen3-Coder-Next UD-Q6_K_XL â€” baseline config (best quality)
#
# 21.4 t/s at 256K context. 80B MoE, ~3B active params/token.
# 13 layers on RTX 4090, 6 layers on RTX 5070 Ti, remaining experts on CPU.
# VRAM: 4090 at 95.8%, 5070 Ti at 93.8%.
#
# Unsloth Dynamic quantization gives higher precision to expert router tensors,
# resulting in better expert selection and no self-correction behavior.
#
# Speed alternative: UD-Q5_K_XL at 25.8 t/s (+21% faster, 15+7 layers).
# Change MODEL path and -ot regex to:
#   MODEL=Qwen3-Coder-Next/UD-Q5_K_XL/Qwen3-Coder-Next-UD-Q5_K_XL-00001-of-00003.gguf
#   -ot blk\.([0-9]|1[0-4])\.=CUDA0,blk\.(1[5-9]|2[0-1])\.=CUDA1,exps=CPU
#
# See docs/llama-cpp-flags-and-qwen3-strategy.md for full details.

MODEL=Qwen3-Coder-Next/UD-Q6_K_XL/Qwen3-Coder-Next-UD-Q6_K_XL-00001-of-00003.gguf
CTX_SIZE=262144
N_GPU_LAYERS=99
FIT=off
EXTRA_ARGS=--jinja -np 1 -b 2048 -ub 2048 --no-context-shift --temp 1.0 --top-p 0.95 --top-k 40 --min-p 0 -ot blk\.([0-9]|1[0-2])\.=CUDA0,blk\.(1[3-8])\.=CUDA1,exps=CPU
