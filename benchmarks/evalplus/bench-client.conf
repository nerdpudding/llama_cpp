# =============================================================================
# bench-client.conf — Client-side config for benchmark code generation
#
# These settings are sent BY the client (codegen) TO the model API.
# They do NOT affect server startup — that's models.conf.
#
# Only models that need special client config are listed here.
# Models without an entry use evalplus.codegen with default behavior
# (no system prompt).
#
# When SYSTEM_PROMPT is set, codegen-custom.py is used instead of
# evalplus.codegen, because evalplus doesn't support system prompts.
# =============================================================================


# GPT-OSS 120B — reasoning level via system prompt trigger.
# Options: "Reasoning: low", "Reasoning: medium", "Reasoning: high"
# See models/documentation/README_modelcard_gpt-oss-120b-GGUF.md
[bench-gpt-oss-120b]
SYSTEM_PROMPT=Reasoning: low
