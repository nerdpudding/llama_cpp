# =============================================================================
# bench-client.conf — Client-side config for benchmark code generation
#
# These settings are sent BY the client (codegen) TO the model API.
# They do NOT affect server startup — that's models.conf.
#
# [defaults] applies to ALL models. Per-model sections override defaults.
#
# When SYSTEM_PROMPT is set for a model, codegen-custom.py is used instead
# of evalplus.codegen, because evalplus doesn't support system prompts.
#
# MAX_TOKENS is patched into evalplus automatically at benchmark start
# (evalplus has no CLI flag for this). Also passed to codegen-custom.py.
# =============================================================================


# Global defaults for all benchmark models
[defaults]
MAX_TOKENS=4096


# GPT-OSS 120B — retired 2026-02-26. Uncomment to reactivate.
# [bench-gpt-oss-120b]
# SYSTEM_PROMPT=Reasoning: high
